---
description:
globs:
alwaysApply: true
---
Here’s a rough roadmap broken into discrete milestones. Tackle them one by one, and you’ll end up with a production-ready CLI tool in Node.js/TypeScript.

1. Project Initialization
   • Create a new git repo and `package.json`
   • Install core deps:
     – commander (CLI)
     – neverthrow (Result-style error handling)
     – typescript, ts-node, @types/node
     – dotenv-cli (env vars)
     – glob (file matching)
     – fs-extra (file I/O)
     – chalk (colored logs)
     – ora (spinners)
     – @vercel/ai (embeddings)
     – chromadb (vector DB client)
   • Add `tsconfig.json` targeting Node, enable `esModuleInterop`
   • Add npm scripts: `build`, `start`, `cli`, `test`

2. CLI Scaffold
   • Create `src/index.ts` and wire up commander
     – Global flags: `--config`, `--verbose`
     – Commands: `index` (build/update index), `generate` (produce docs)
   • Hook `#!/usr/bin/env node` + bin entry in `package.json`
   • Integrate chalk & ora for nicer console output

3. Error-Handling Utilities
   • Create a small wrapper around Promise calls using neverthrow’s `Result`
   • Expose helpers: `fromThrowable()`, `wrapAsync()`
   • Update CLI actions to return `Result` and early-exit on `.isErr()`

4. AST-Based Splitting Module
   • In `src/astSplitter.ts`, implement `astSplitFile(path): Chunk[]` using the TypeScript Compiler API
     – Split on functions, classes, interfaces, enums, variable statements
     – Record `chunkId`, `symbol`, `startLine`, `endLine`
   • Unit-test with a few `.ts` snippets (using Jest or your preferred test runner)

5. Manifest Management
   • In `src/manifest.ts`, read/write a JSON manifest mapping `chunkId → hash`
   • Provide `diff(oldManifest, newChunks): { added, changed, removed }`

6. Indexing Command (CLI: `index`)
   • Walk your `src/` tree with glob → list `.ts/.js` files
   • For each file, call `astSplitFile`, compute SHA-1 hash of each chunk
   • Use `manifest.diff` to find only new/changed chunks
   • Batch-embed those with `new OpenAIEmbeddings({ model: … })` from `@vercel/ai`
   • Upsert into Chroma via `chromadb` (ids = chunkId, embeddings, documents, metadatas)
   • Remove any deleted‐chunk IDs from the vector store
   • Write the updated manifest

7. Retrieval + Documentation Generation Module
   • In `src/docgen.ts`, export a function that:
     – Accepts a list of “sections” (title + semantic query)
     – For each: embed the query, fetch top-K chunks from Chroma
     – Build context with Markdown code blocks + hyperlinks (use your repo’s base URL + `path#Lstart-Lend`)
     – Call OpenAI Chat Completion (`gpt-4`) via `@vercel/ai` or the official `openai` SDK to draft each section in Markdown
     – Aggregate into a single `book.md`

8. Generate Command (CLI: `generate`)
   • Wire commander’s `generate` to invoke `docgen`
   • Pass in section definitions (via a JSON/YAML spec or CLI flags)
   • Output `docs/book.md` (or custom path)

9. Configuration & CI/CD
   • Support a `config.json` or `dotenv` for API keys, repo URL, chunk size, etc.
   • Add a GitHub Action to run `npm run cli index` on push, and optionally `generate` on demand
   • Publish your CLI via npm (if open‐source)

10. Testing & Polish
   • Write unit tests for splitting, manifest diff, error wrappers
   • Add end-to-end test: run `cli index && cli generate` on a small sample repo
   • Document usage in `README.md`

––
Work through each task in order, commit often, and you’ll have a robust, AST-aware, incremental indexing + doc-generation CLI using commander & neverthrow.
