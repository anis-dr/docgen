---
description:
globs:
alwaysApply: true
---
Here’s a rough roadmap broken into discrete milestones. Tackle them one by one, and you’ll end up with a production-ready CLI tool in Node.js/TypeScript.

1. Project Initialization
   • Create a new git repo and `package.json`
   • Install core deps:
     – commander (CLI)
     – neverthrow (Result-style error handling)
     – typescript, ts-node, @types/node
     – dotenv-cli (env vars)
     – glob (file matching)
     – fs-extra (file I/O)
     – chalk (colored logs)
     – ora (spinners)
     – ai (Vercel AI SDK, core for embeddings/completions)
     – @ai-sdk/openai (OpenAI provider for ai)
     – chromadb (vector DB client)
   • Add `tsconfig.json` targeting Node, enable `esModuleInterop`
   • Add npm scripts: `build`, `start`, `cli`, `test`

2. CLI Scaffold
   • Create `src/index.ts` and wire up commander
     – Global flags: `--config`, `--verbose`
     – Commands: `index` (build/update index), `generate` (produce docs)
   • Hook `#!/usr/bin/env node` + bin entry in `package.json`
   • Integrate chalk & ora for nicer console output

3. Error-Handling Utilities
   • Create a small wrapper around Promise calls using neverthrow’s `Result`
   • Expose helpers: `fromThrowable()`, `wrapAsync()`
   • Update CLI actions to return `Result` and early-exit on `.isErr()`

4. AST-Based Splitting Module
   • In `src/astSplitter.ts`, implement `astSplitFile(path): Chunk[]` using the TypeScript Compiler API
     – Split on functions, classes, interfaces, enums, variable statements
     – Record `chunkId`, `symbol`, `startLine`, `endLine`
   • Unit-test with a few `.ts` snippets (using Vitest)

5. Manifest Management
   • In `src/manifest.ts`, read/write a JSON manifest mapping `chunkId → hash`
   • Provide `diff(oldManifest, newChunks): { added, changed, removed }`

6. Indexing Command (CLI: `index`)
   • Walk your `src/` tree with glob → list `.ts/.js` files
   • For each file, call `astSplitFile`, compute SHA-1 hash of each chunk
   • Use `manifest.diff` to find only new/changed chunks
   • Batch-embed those with `embed` or `embedMany` from `ai` using `openai.embedding('text-embedding-3-small')` or similar via `@ai-sdk/openai`
   • Upsert into Chroma via `chromadb` (ids = chunkId, embeddings, documents, metadatas)
   • Remove any deleted‐chunk IDs from the vector store
   • Write the updated manifest

   Example (single):
   ```ts
   import { embed } from 'ai';
   import { openai } from '@ai-sdk/openai';
   const { embedding } = await embed({
     model: openai.embedding('text-embedding-3-small'),
     value: 'sunny day at the beach',
   });
   ```
   Example (batch):
   ```ts
   import { embedMany } from 'ai';
   import { openai } from '@ai-sdk/openai';
   const { embeddings } = await embedMany({
     model: openai.embedding('text-embedding-3-small'),
     values: [
       'sunny day at the beach',
       'rainy afternoon in the city',
       'snowy night in the mountains',
     ],
   });
   ```
   See: https://ai-sdk.dev/docs/ai-sdk-core/embeddings#embedding-a-single-value

7. Retrieval + Documentation Generation Module
   • In `src/docgen.ts`, export a function that:
     – Accepts a list of “sections” (title + semantic query)
     – For each: embed the query, fetch top-K chunks from Chroma
     – Build context with Markdown code blocks + hyperlinks (use your repo’s base URL + `path#Lstart-Lend`)
     – Call `generateText` or `generateObject` from `ai` (with `openai('gpt-4o')` or similar) to draft each section in Markdown
     – Aggregate into a single `book.md`

8. Generate Command (CLI: `generate`)
   • Wire commander’s `generate` to invoke `docgen`
   • Pass in section definitions (via a JSON/YAML spec or CLI flags)
   • Output `docs/book.md` (or custom path)

9. Configuration & CI/CD
   • Support a `config.json` or `dotenv` for API keys, repo URL, chunk size, etc.
   • Add a GitHub Action to run `npm run cli index` on push, and optionally `generate` on demand
   • Publish your CLI via npm (if open‐source)

10. Testing & Polish
   • Write unit tests for splitting, manifest diff, error wrappers
   • Add end-to-end test: run `cli index && cli generate` on a small sample repo
   • Document usage in `README.md`

––
Work through each task in order, commit often, and you’ll have a robust, AST-aware, incremental indexing + doc-generation CLI using commander & neverthrow.

// NOTE: Use `OPENAI_API_KEY` in your env for OpenAI models. See ai SDK docs for details.
